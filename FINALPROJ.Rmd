---
title: "FinalProj"
output: html_document
date: "2023-03-29"
---
Libraries
```{r}
library(tidyverse)
library(tidytext)
library(wordcloud)
library(topicmodels)
library(gridExtra)
library(shiny)
```

MAP DATA -  
```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

SENTIMENT ANALYSIS-

```{r, Data Prep}
# Load Data
tweets = read_csv("Tweets-1.csv")

#Tokenize and Remove Stop Words

custom_stop_words <- tribble(
  # Column names should match stop_words
  ~word, ~lexicon,
  # Add http, win, and t.co as custom stop words
  "http", "CUSTOM",
  "win", "CUSTOM",
  "t.co", "CUSTOM",
  "virginamerica", "CUSTOM",
  "sfo", "CUSTOM",
)
# Bind the custom stop words to stop_words
stop_words2 <- stop_words %>% 
   bind_rows(custom_stop_words)
#
tidy_twitter <- tweets %>% 
  
  select_if(~!any(is.na(.)))  %>% 
  # Tokenize the twitter data
  unnest_tokens(word, text) %>% 
  # Remove stop words
  anti_join(stop_words2) %>%
  # Remove incoherent words and numbers using grepl
  filter(!grepl("\\b\\d+\\b|[^[:alpha:]]", word)) %>%
 
  filter(nchar(word) > 2)


```

```{r, Visualisation without a Sentiment Dictionary}

#General sentiment count
tidy_twitter %>% count(airline_sentiment)

#Most frequent words in neutral
word_counts <- tidy_twitter %>% 
  filter(airline_sentiment == "neutral") %>% 
  count(word) %>%  
  filter(n > 100) %>% 
  arrange(desc(n))  

ggplot(word_counts, aes(reorder(word, n), n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Word", y = "Count")+ggtitle("neutral")

#Most frequent words in Positive
word_counts <- tidy_twitter %>% 
  filter(airline_sentiment == "positive") %>% 
  count(word) %>%  
  filter(n > 100) %>% 
  arrange(desc(n))  

ggplot(word_counts, aes(reorder(word, n), n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Word", y = "Count")+ggtitle("positive")

#Most frequent words in negative
word_counts <- tidy_twitter %>% 
  filter(airline_sentiment == "negative") %>% 
  count(word) %>%  
  filter(n > 400) %>% 
  arrange(desc(n))  

ggplot(word_counts, aes(reorder(word, n), n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Word", y = "Count")+ggtitle("Negative")

# Top 20 Sentiments compared
word_counts <- tidy_twitter %>%
  # Count words by whether or not its a complaint
  count(word, airline_sentiment) %>%
  # Group by whether or not its a complaint
  group_by(airline_sentiment) %>%
  # Keep the top 20 words
  slice_max(n, n = 20) %>%
  # Ungroup before reordering word as a factor by the count
  ungroup() %>%
  mutate(word2 = fct_reorder(word, n))

ggplot(word_counts, aes(x = word2, y = n, fill  = airline_sentiment)) +
  # Don't include the lengend for the column plot
  geom_col(show.legend = FALSE) +
  # Facet by whether or not its a complaint and make the y-axis free
  facet_wrap(~airline_sentiment, scales = "free_y") +
  # Flip the coordinates and add a title: "Twitter Word Counts"
   coord_flip() +
   ggtitle("Sentiment Comparison") 

```

```{r, Word Cloud}
#Word Cloud
word_counts <- tidy_twitter %>% 
  count(word)

# Define the color palette with more interpolated colors
color_palette <- colorRampPalette(brewer.pal(8, "Dark2"))(300)

wordcloud(
  words = word_counts$word,
  freq = word_counts$n,
  max.words = 300,
  colors = color_palette,
  random.order = FALSE,
  rot.per = 0.35,
  scale = c(3, 0.5)
)

```

```{r, Sentiment Dictionary vs Airline_sentiments}
#Sorting the original data using the dictionary

sentiment_twitter <- tidy_twitter %>% 
  inner_join(get_sentiments("nrc"))
 

  # Count by complaint label and sentiment
 count1 = sentiment_twitter  %>% count(airline_sentiment, sentiment) %>% 
  # Spread the sentiment and count columns
  pivot_wider(names_from = sentiment,values_from = n)

#The words in the dataframe are grouped by the sentiments Potitive, negative and neutral. The graph shows how many of the NRC sentiment words are in the original sentiments (Load sentiment_melted dataframe for more context)
sentiment_melted <- count1 %>%
  tidyr::pivot_longer(cols = -airline_sentiment, names_to = "sentiment", values_to = "count")

# Create a bar plot
ggplot(sentiment_melted, aes(x = airline_sentiment, y = count, fill = sentiment)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Airline Sentiment Type(provided by the original Data)", y = "Airline Sentiment Frequency ", title = "NRC sentiments vs Airline Sentiment", fill = "NRC Dictionary Sentiments") +
  theme_minimal()

#Since there are more categories in NRC sentiment Dictionary, the distribution of positive and negative words are different in sentiment_twitter df as compared to the original data frame, tidy_twitter. According to the original sentiments provided by the airline_sentiment column (in tidy_twitter df), there are more negative words than positive words. However according to the NRC dictionary (sentiment_twitter df), positive words have the most frequency. This is just an illusion because in both these data frames, sentiments are categorized differently. NRC dictionary has a lot more categories, thus splitting the original negative words list into more categories. Another reason this is happening is because the sentiment_twitter df is half the size of the original dataframe.There's a graph below highlighting the discrepancy 

####

```

```{r, Data Discrepancy(read above chunk)}

word_count <- tidy_twitter %>% 
  count(airline_sentiment, sort = TRUE)

# Create a simple ggplot of word count
g1 = ggplot(word_count, aes(x = airline_sentiment, y = n)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "Words", y = "Count") +
  ggtitle("Without NRC dictionary")

###
word_count1 <- sentiment_twitter %>% 
  count(sentiment) %>%
  arrange(desc(n))

# Create a simple ggplot of word count in descending order
g2 = ggplot(word_count1, aes(x = reorder(sentiment, -n), y = n)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "Words", y = "Count") +
  ggtitle("With NRC dictionary")

grid.arrange(g1,g2,ncol = 2)

```

```{r, Topic Modeling and Pattern Analysis}

#Topic modeling is a probabilistic model used to extract hidden patterns in a large collection of text. (the specifics are in datacamp -> "Introduction to Text Analysis in R" course ->  Topic modeling (last section)-> "Interpreting Topics" video)

dtm_twitter <- tidy_twitter %>% 
  count(word, tweet_id) %>% 
  # Cast the word counts by tweet into a DTM
  cast_dtm(tweet_id, word, n)

# Coerce dtm_twitter into a matrix called matrix_twitter
matrix_twitter <- as.matrix(dtm_twitter)

##
lda_out2 <- LDA(
  dtm_twitter,  k = 3,  method = "Gibbs",
  control = list(seed = 42)
)

# Tidy the matrix of word probabilities
lda_topics2 <- lda_out2 %>%   tidy(matrix = "beta")

# Arrange the topics by word probabilities in descending order
lda_topics2  %>% 
  arrange(desc(beta))

#
word_probs2 <- lda_topics2 %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  mutate(term2 = fct_reorder(term, beta))

# Plot word probs, color and facet based on topic
ggplot(
  word_probs2, 
  aes(term2, beta, fill = as.factor(topic))
) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

```

 SHINY -

```{r, UI}

ui <- fluidPage(
  titlePanel("Airline Sentiment Analysis"),
  
  sidebarLayout(
    sidebarPanel(
      selectInput("x_axis", "Choose X-axis variable:",
                  choices = c("word", "airline_sentiment"),
                  selected = "word"),
      selectInput("y_axis", "Choose Y-axis variable:",
                  choices = c("n"),
                  selected = "n"),
      conditionalPanel(
        condition = "input.x_axis == 'word'",
        actionButton("word_cloud", "Show Word Cloud")
      )
    ),
    
    mainPanel(
      plotOutput("sentimentPlot"),
      plotOutput("wordCloudPlot", height = "400px")
    )
  )
)


```

```{r, Server}
server <- function(input, output) {
  
  output$sentimentPlot <- renderPlot({
    
    if (input$x_axis == "word") {
      word_counts <- tidy_twitter %>%
        count(word, airline_sentiment) %>%
        filter(n > 100) %>%
        arrange(desc(n)) %>%
        head(100)
      
      ggplot(word_counts, aes_string(x = input$x_axis, y = input$y_axis, fill = "airline_sentiment")) +
        geom_col() +
        coord_flip() +
        labs(x = input$x_axis, y = input$y_axis)
    } else {
      sentiment_counts <- tidy_twitter %>%
        count(airline_sentiment) %>%
        arrange(desc(n))
      
      ggplot(sentiment_counts, aes_string(x = input$x_axis, y = input$y_axis)) +
        geom_col() +
        labs(x = input$x_axis, y = input$y_axis)
    }
  })
  
  output$wordCloudPlot <- renderPlot({
    if (input$word_cloud > 0) {
      word_counts <- tidy_twitter %>%
        count(word) %>%
        head(100)
      
      color_palette <- colorRampPalette(brewer.pal(8, "Dark2"))(300)
      
      wordcloud(
        words = word_counts$word,
        freq = word_counts$n,
        max.words = 100,
        colors = color_palette,
        random.order = FALSE,
        rot.per = 0.35,
        scale = c(3, 0.5)
      )
    } else {
      return(NULL)
    }
  })
}



```

```{r, Run App (Without NRC)}
shinyApp(ui = ui, server = server)

```

```{r, UI2}
ui2 <- fluidPage(
  titlePanel("Sentiment Twitter Analysis"),
  
  sidebarLayout(
    sidebarPanel(
      h3("Sentiment Analysis based on NRC Dictionary"),
      selectInput("x_axis2", "Choose X-axis variable:",
                  choices = c("word", "sentiment"),
                  selected = "word"),
      selectInput("y_axis2", "Choose Y-axis variable:",
                  choices = c("sentiment", "word"),
                  selected = "sentiment")
    ),
    
    mainPanel(
      plotOutput("sentimentBarPlot2")
    )
  )
)



```

```{r, Server2}
server2 <- function(input, output) {
  
  output$sentimentBarPlot2 <- renderPlot({
    
    if (input$x_axis2 == "word") {
      top_words <- sentiment_twitter %>%
        count(word, sentiment) %>%
        group_by(sentiment) %>%
        top_n(20, n) %>%
        ungroup()

      ggplot(top_words, aes(x = reorder(word, n), y = n, fill = sentiment)) +
        geom_col() +
        coord_flip() +
        labs(x = "Word", y = "Count") +
        facet_wrap(~ sentiment, scales = "free_y")
    } else {
      sentiment_counts <- sentiment_twitter %>%
        count(sentiment) %>%
        arrange(desc(n))

      ggplot(sentiment_counts, aes(x = sentiment, y = n)) +
        geom_col() +
        labs(x = "Sentiment", y = "Count")
    }
  })
}



```

```{r, Run App (With NRC Dictionary)}
shinyApp(ui = ui2, server = server2)

```
